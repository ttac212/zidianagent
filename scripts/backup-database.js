#!/usr/bin/env node
/**
 * æ™ºç‚¹AIå¹³å° - æ•°æ®åº“å¤‡ä»½è„šæœ¬
 * 
 * åŠŸèƒ½:
 * 1. æ”¯æŒSQLiteå’ŒPostgreSQLæ•°æ®åº“å¤‡ä»½
 * 2. è‡ªåŠ¨åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶
 * 3. æ”¯æŒå¤šç§å¤‡ä»½ç­–ç•¥(å®Œæ•´å¤‡ä»½/å¢é‡å¤‡ä»½/ç»“æ„å¤‡ä»½)
 * 4. è‡ªåŠ¨æ¸…ç†è¿‡æœŸå¤‡ä»½æ–‡ä»¶
 * 
 * ä½¿ç”¨æ–¹æ³•:
 * node scripts/backup-database.js [é€‰é¡¹]
 * 
 * é€‰é¡¹:
 * --type=full|schema|data    å¤‡ä»½ç±»å‹(é»˜è®¤:full)
 * --keep=7                   ä¿ç•™å¤©æ•°(é»˜è®¤:7å¤©)
 * --format=db|sql            å¤‡ä»½æ ¼å¼(é»˜è®¤:db)
 * --compress                 æ˜¯å¦å‹ç¼©(å¯é€‰)
 */

const fs = require('fs')
const path = require('path')
const { execSync, spawn } = require('child_process')
const { createReadStream, createWriteStream } = require('fs')
const { createGzip } = require('zlib')

// å¤‡ä»½é…ç½®
const BACKUP_CONFIG = {
  // å¤‡ä»½ç›®å½•
  backupDir: path.join(__dirname, '../backups/database'),
  
  // SQLiteæ•°æ®åº“è·¯å¾„
  sqliteDbPath: path.join(__dirname, '../prisma/dev.db'),
  
  // Prisma Schemaè·¯å¾„
  schemaPath: path.join(__dirname, '../prisma/schema.prisma'),
  
  // é»˜è®¤ä¿ç•™å¤©æ•°
  defaultKeepDays: 7,
  
  // æ”¯æŒçš„å¤‡ä»½ç±»å‹
  backupTypes: ['full', 'schema', 'data'],
  
  // æ”¯æŒçš„å¤‡ä»½æ ¼å¼
  formats: ['db', 'sql']
}

class DatabaseBackup {
  constructor(options = {}) {
    this.options = {
      type: options.type || 'full',
      keepDays: parseInt(options.keep) || BACKUP_CONFIG.defaultKeepDays,
      format: options.format || 'db',
      compress: options.compress || false,
      ...options
    }
    
    this.timestamp = new Date().toISOString().replace(/[:.]/g, '-').split('.')[0]
    this.backupDir = path.join(BACKUP_CONFIG.backupDir, new Date().toISOString().split('T')[0])
  }

  /**
   * æ‰§è¡Œæ•°æ®åº“å¤‡ä»½
   */
  async execute() {
    try {
      console.log(`ğŸš€ å¼€å§‹æ•°æ®åº“å¤‡ä»½ - ç±»å‹: ${this.options.type}, æ ¼å¼: ${this.options.format}`)
      
      // åˆ›å»ºå¤‡ä»½ç›®å½•
      await this.ensureBackupDirectory()
      
      // æ‰§è¡Œå¤‡ä»½
      const backupFile = await this.performBackup()
      
      // éªŒè¯å¤‡ä»½
      await this.verifyBackup(backupFile)
      
      // æ¸…ç†è¿‡æœŸå¤‡ä»½
      await this.cleanupOldBackups()
      
      // ç”Ÿæˆå¤‡ä»½æŠ¥å‘Š
      const report = await this.generateBackupReport(backupFile)
      
      console.log(`âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ!`)
      console.log(`ğŸ“ å¤‡ä»½æ–‡ä»¶: ${backupFile}`)
      console.log(`ğŸ“Š å¤‡ä»½æŠ¥å‘Š: ${JSON.stringify(report, null, 2)}`)
      
      return { success: true, backupFile, report }
      
    } catch (error) {
      console.error(`âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥:`, error.message)
      throw error
    }
  }

  /**
   * ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
   */
  async ensureBackupDirectory() {
    if (!fs.existsSync(this.backupDir)) {
      fs.mkdirSync(this.backupDir, { recursive: true })
      console.log(`ğŸ“ åˆ›å»ºå¤‡ä»½ç›®å½•: ${this.backupDir}`)
    }
  }

  /**
   * æ‰§è¡Œå®é™…å¤‡ä»½æ“ä½œ
   */
  async performBackup() {
    const databaseUrl = process.env.DATABASE_URL || `file:${BACKUP_CONFIG.sqliteDbPath}`
    
    if (databaseUrl.includes('sqlite') || databaseUrl.startsWith('file:')) {
      return await this.backupSQLite()
    } else if (databaseUrl.includes('postgresql')) {
      return await this.backupPostgreSQL()
    } else {
      throw new Error('ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹')
    }
  }

  /**
   * SQLiteæ•°æ®åº“å¤‡ä»½
   */
  async backupSQLite() {
    const backupFileName = `sqlite_${this.options.type}_${this.timestamp}`
    let backupFile
    
    switch (this.options.type) {
      case 'full':
        // å®Œæ•´å¤‡ä»½ - ç›´æ¥å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
        backupFile = path.join(this.backupDir, `${backupFileName}.db`)
        fs.copyFileSync(BACKUP_CONFIG.sqliteDbPath, backupFile)
        
        // åŒæ—¶å¤‡ä»½schemaæ–‡ä»¶
        const schemaBackupFile = path.join(this.backupDir, `schema_${this.timestamp}.prisma`)
        fs.copyFileSync(BACKUP_CONFIG.schemaPath, schemaBackupFile)
        
        console.log(`ğŸ“‹ å·²å¤‡ä»½æ•°æ®åº“æ–‡ä»¶å’ŒSchema`)
        break
        
      case 'schema':
        // ä»…å¤‡ä»½æ•°æ®åº“ç»“æ„
        backupFile = path.join(this.backupDir, `${backupFileName}.sql`)
        await this.exportSQLiteSchema(backupFile)
        break
        
      case 'data':
        // ä»…å¤‡ä»½æ•°æ® (SQLiteè¾ƒå¤æ‚,ä½¿ç”¨å®Œæ•´å¤‡ä»½)
        backupFile = path.join(this.backupDir, `${backupFileName}_dataonly.db`)
        fs.copyFileSync(BACKUP_CONFIG.sqliteDbPath, backupFile)
        console.log(`ğŸ“Š å·²å¤‡ä»½æ•°æ® (SQLiteå®Œæ•´æ–‡ä»¶)`)
        break
        
      default:
        throw new Error(`ä¸æ”¯æŒçš„å¤‡ä»½ç±»å‹: ${this.options.type}`)
    }

    // å¯é€‰å‹ç¼©
    if (this.options.compress) {
      const compressedFile = await this.compressFile(backupFile)
      fs.unlinkSync(backupFile) // åˆ é™¤æœªå‹ç¼©æ–‡ä»¶
      backupFile = compressedFile
    }

    return backupFile
  }

  /**
   * PostgreSQLæ•°æ®åº“å¤‡ä»½
   */
  async backupPostgreSQL() {
    const backupFileName = `postgres_${this.options.type}_${this.timestamp}.sql`
    const backupFile = path.join(this.backupDir, backupFileName)
    
    // è§£ææ•°æ®åº“è¿æ¥ä¿¡æ¯
    const dbUrl = new URL(process.env.DATABASE_URL)
    const dbConfig = {
      host: dbUrl.hostname,
      port: dbUrl.port || 5432,
      username: dbUrl.username,
      password: dbUrl.password,
      database: dbUrl.pathname.slice(1)
    }

    let pgDumpCmd
    
    switch (this.options.type) {
      case 'full':
        pgDumpCmd = `PGPASSWORD="${dbConfig.password}" pg_dump -h ${dbConfig.host} -p ${dbConfig.port} -U ${dbConfig.username} -d ${dbConfig.database}`
        break
        
      case 'schema':
        pgDumpCmd = `PGPASSWORD="${dbConfig.password}" pg_dump -h ${dbConfig.host} -p ${dbConfig.port} -U ${dbConfig.username} -d ${dbConfig.database} --schema-only`
        break
        
      case 'data':
        pgDumpCmd = `PGPASSWORD="${dbConfig.password}" pg_dump -h ${dbConfig.host} -p ${dbConfig.port} -U ${dbConfig.username} -d ${dbConfig.database} --data-only`
        break
        
      default:
        throw new Error(`ä¸æ”¯æŒçš„å¤‡ä»½ç±»å‹: ${this.options.type}`)
    }

    try {
      console.log(`ğŸ”„ æ‰§è¡ŒPostgreSQLå¤‡ä»½å‘½ä»¤...`)
      const output = execSync(pgDumpCmd, { encoding: 'utf8', maxBuffer: 50 * 1024 * 1024 })
      fs.writeFileSync(backupFile, output)
      console.log(`ğŸ’¾ PostgreSQLå¤‡ä»½å®Œæˆ`)
      
    } catch (error) {
      throw new Error(`PostgreSQLå¤‡ä»½å¤±è´¥: ${error.message}`)
    }

    // å¯é€‰å‹ç¼©
    if (this.options.compress) {
      const compressedFile = await this.compressFile(backupFile)
      fs.unlinkSync(backupFile)
      return compressedFile
    }

    return backupFile
  }

  /**
   * å¯¼å‡ºSQLiteæ•°æ®åº“ç»“æ„
   */
  async exportSQLiteSchema(outputFile) {
    return new Promise((resolve, reject) => {
      const child = spawn('node', ['-e', `
        const { PrismaClient } = require('@prisma/client')
        const fs = require('fs')
        
        async function exportSchema() {
          const prisma = new PrismaClient()
          try {
            // è·å–æ‰€æœ‰è¡¨çš„ç»“æ„
            const tables = await prisma.$queryRaw\`
              SELECT sql FROM sqlite_master 
              WHERE type='table' AND name NOT LIKE 'sqlite_%'
            \`
            
            let schemaSQL = '-- SQLite Schema Export\\n'
            schemaSQL += '-- Generated on: ' + new Date().toISOString() + '\\n\\n'
            
            tables.forEach(table => {
              if (table.sql) {
                schemaSQL += table.sql + ';\\n\\n'
              }
            })
            
            fs.writeFileSync('${outputFile}', schemaSQL)
            console.log('Schema exported successfully')
            
          } catch (error) {
            console.error('Schema export failed:', error)
            process.exit(1)
          } finally {
            await prisma.$disconnect()
          }
        }
        
        exportSchema()
      `])

      child.on('close', (code) => {
        if (code === 0) {
          console.log(`ğŸ“‹ æ•°æ®åº“ç»“æ„å·²å¯¼å‡ºåˆ°: ${outputFile}`)
          resolve()
        } else {
          reject(new Error(`Schemaå¯¼å‡ºå¤±è´¥ï¼Œé€€å‡ºç : ${code}`))
        }
      })
    })
  }

  /**
   * å‹ç¼©å¤‡ä»½æ–‡ä»¶
   */
  async compressFile(filePath) {
    return new Promise((resolve, reject) => {
      const compressedPath = `${filePath}.gz`
      const readStream = createReadStream(filePath)
      const writeStream = createWriteStream(compressedPath)
      const gzip = createGzip()

      readStream
        .pipe(gzip)
        .pipe(writeStream)
        .on('finish', () => {
          console.log(`ğŸ—œï¸  æ–‡ä»¶å·²å‹ç¼©: ${path.basename(compressedPath)}`)
          resolve(compressedPath)
        })
        .on('error', reject)
    })
  }

  /**
   * éªŒè¯å¤‡ä»½æ–‡ä»¶
   */
  async verifyBackup(backupFile) {
    try {
      const stats = fs.statSync(backupFile)
      
      if (stats.size === 0) {
        throw new Error('å¤‡ä»½æ–‡ä»¶ä¸ºç©º')
      }
      
      console.log(`âœ… å¤‡ä»½æ–‡ä»¶éªŒè¯é€šè¿‡ - å¤§å°: ${this.formatFileSize(stats.size)}`)
      
      // å¯¹äºSQLiteæ–‡ä»¶ï¼Œå¯ä»¥å°è¯•æ‰“å¼€éªŒè¯
      if (backupFile.endsWith('.db') && !backupFile.endsWith('.gz')) {
        await this.verifySQLiteBackup(backupFile)
      }
      
      return true
      
    } catch (error) {
      throw new Error(`å¤‡ä»½æ–‡ä»¶éªŒè¯å¤±è´¥: ${error.message}`)
    }
  }

  /**
   * éªŒè¯SQLiteå¤‡ä»½æ–‡ä»¶
   */
  async verifySQLiteBackup(backupFile) {
    return new Promise((resolve, reject) => {
      const child = spawn('node', ['-e', `
        const { PrismaClient } = require('@prisma/client')
        
        async function verifyBackup() {
          const prisma = new PrismaClient({
            datasources: {
              db: { url: 'file:${backupFile}' }
            }
          })
          
          try {
            // å°è¯•æŸ¥è¯¢ç”¨æˆ·è¡¨éªŒè¯
            const userCount = await prisma.user.count()
            console.log(\`éªŒè¯æˆåŠŸ - ç”¨æˆ·æ•°: \${userCount}\`)
            
          } catch (error) {
            console.error('å¤‡ä»½æ–‡ä»¶éªŒè¯å¤±è´¥:', error.message)
            process.exit(1)
          } finally {
            await prisma.$disconnect()
          }
        }
        
        verifyBackup()
      `])

      child.on('close', (code) => {
        if (code === 0) {
          console.log(`âœ… SQLiteå¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡`)
          resolve()
        } else {
          reject(new Error(`SQLiteå¤‡ä»½éªŒè¯å¤±è´¥`))
        }
      })
    })
  }

  /**
   * æ¸…ç†è¿‡æœŸå¤‡ä»½æ–‡ä»¶
   */
  async cleanupOldBackups() {
    try {
      const backupRootDir = BACKUP_CONFIG.backupDir
      const cutoffDate = new Date()
      cutoffDate.setDate(cutoffDate.getDate() - this.options.keepDays)
      
      if (!fs.existsSync(backupRootDir)) {
        return
      }

      const directories = fs.readdirSync(backupRootDir)
        .filter(dir => {
          const dirPath = path.join(backupRootDir, dir)
          return fs.statSync(dirPath).isDirectory()
        })

      let cleanedCount = 0
      let cleanedSize = 0

      for (const dir of directories) {
        const dirDate = new Date(dir)
        
        if (dirDate < cutoffDate) {
          const dirPath = path.join(backupRootDir, dir)
          const files = fs.readdirSync(dirPath)
          
          for (const file of files) {
            const filePath = path.join(dirPath, file)
            const stats = fs.statSync(filePath)
            cleanedSize += stats.size
            fs.unlinkSync(filePath)
          }
          
          fs.rmdirSync(dirPath)
          cleanedCount++
          console.log(`ğŸ—‘ï¸  å·²åˆ é™¤è¿‡æœŸå¤‡ä»½ç›®å½•: ${dir}`)
        }
      }

      if (cleanedCount > 0) {
        console.log(`ğŸ§¹ æ¸…ç†å®Œæˆ - åˆ é™¤ ${cleanedCount} ä¸ªè¿‡æœŸå¤‡ä»½ç›®å½•ï¼Œé‡Šæ”¾ç©ºé—´ ${this.formatFileSize(cleanedSize)}`)
      }

    } catch (error) {
      console.warn(`âš ï¸  æ¸…ç†è¿‡æœŸå¤‡ä»½æ—¶å‡ºç°è­¦å‘Š: ${error.message}`)
    }
  }

  /**
   * ç”Ÿæˆå¤‡ä»½æŠ¥å‘Š
   */
  async generateBackupReport(backupFile) {
    const stats = fs.statSync(backupFile)
    
    const report = {
      timestamp: new Date().toISOString(),
      backupType: this.options.type,
      backupFormat: this.options.format,
      backupFile: path.basename(backupFile),
      fileSize: stats.size,
      fileSizeFormatted: this.formatFileSize(stats.size),
      compressed: this.options.compress,
      keepDays: this.options.keepDays,
      databaseType: process.env.DATABASE_URL?.includes('postgresql') ? 'PostgreSQL' : 'SQLite'
    }

    // ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
    const reportFile = path.join(this.backupDir, `backup_report_${this.timestamp}.json`)
    fs.writeFileSync(reportFile, JSON.stringify(report, null, 2))

    return report
  }

  /**
   * æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
   */
  formatFileSize(bytes) {
    if (bytes === 0) return '0 Bytes'
    
    const k = 1024
    const sizes = ['Bytes', 'KB', 'MB', 'GB']
    const i = Math.floor(Math.log(bytes) / Math.log(k))
    
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i]
  }
}

// å‘½ä»¤è¡Œæ¥å£
async function main() {
  try {
    // è§£æå‘½ä»¤è¡Œå‚æ•°
    const args = process.argv.slice(2)
    const options = {}
    
    args.forEach(arg => {
      if (arg.startsWith('--')) {
        const [key, value] = arg.substring(2).split('=')
        options[key] = value || true
      }
    })

    // æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if (options.help) {
      console.log(`
æ™ºç‚¹AIå¹³å° - æ•°æ®åº“å¤‡ä»½å·¥å…·

ä½¿ç”¨æ–¹æ³•:
  node scripts/backup-database.js [é€‰é¡¹]

é€‰é¡¹:
  --type=full|schema|data    å¤‡ä»½ç±»å‹ (é»˜è®¤: full)
    full    - å®Œæ•´å¤‡ä»½(æ•°æ®+ç»“æ„)
    schema  - ä»…å¤‡ä»½æ•°æ®åº“ç»“æ„
    data    - ä»…å¤‡ä»½æ•°æ®
  
  --keep=7                   ä¿ç•™å¤©æ•° (é»˜è®¤: 7å¤©)
  --format=db|sql           å¤‡ä»½æ ¼å¼ (é»˜è®¤: db)
  --compress                æ˜¯å¦å‹ç¼©å¤‡ä»½æ–‡ä»¶
  --help                    æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  node scripts/backup-database.js                    # é»˜è®¤å®Œæ•´å¤‡ä»½
  node scripts/backup-database.js --type=schema      # ä»…å¤‡ä»½ç»“æ„
  node scripts/backup-database.js --compress         # å‹ç¼©å¤‡ä»½
  node scripts/backup-database.js --keep=30          # ä¿ç•™30å¤©
      `)
      return
    }

    // æ‰§è¡Œå¤‡ä»½
    const backup = new DatabaseBackup(options)
    const result = await backup.execute()
    
    console.log(`\nğŸ‰ å¤‡ä»½ä»»åŠ¡å®Œæˆ!`)
    process.exit(0)
    
  } catch (error) {
    console.error(`\nğŸ’¥ å¤‡ä»½ä»»åŠ¡å¤±è´¥:`, error.message)
    process.exit(1)
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬
if (require.main === module) {
  main()
}

module.exports = { DatabaseBackup }