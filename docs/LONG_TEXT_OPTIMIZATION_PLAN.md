# é•¿æ–‡æœ¬å¯¹è¯åœºæ™¯ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“Š è°ƒç ”æ€»ç»“ï¼ˆ2025å¹´ä¸šç•Œæœ€ä½³å®è·µï¼‰

### 1. LLMé•¿ä¸Šä¸‹æ–‡çª—å£ä¼˜åŒ–è¦ç‚¹

**æ ¸å¿ƒå‘ç°ï¼š**
- âŒ **æ›´å¤§ä¸æ€»æ˜¯æ›´å¥½**ï¼šLlama-3.1-405båœ¨32kåæ€§èƒ½ä¸‹é™ï¼ŒGPT-4åœ¨64kåä¸‹é™
- âœ… **ç»“æ„åŒ–æç¤º**ï¼šå¤§ä¸Šä¸‹æ–‡éœ€è¦ç²¾å¿ƒç»„ç»‡ä¿¡æ¯
- âœ… **è¿­ä»£å¼€å‘**ï¼šå…ˆç®€å•å®ç°ï¼ŒéªŒè¯åå¢å¼º
- âœ… **RAGæ€§èƒ½**ï¼šæ£€ç´¢+é•¿ä¸Šä¸‹æ–‡ç»“åˆæ•ˆæœæœ€ä½³

**Claude Sonnet 4 (2025) æœ€æ–°æŠ€æœ¯ï¼š**
- ğŸ¯ **1M context window**ï¼ˆæµ‹è¯•ç‰ˆï¼‰ï¼š5å€å¢é•¿
- ğŸ’° **Prompt Caching**ï¼šå‡å°‘å»¶è¿Ÿå’Œæˆæœ¬
- ğŸ“¦ **Batch Processing**ï¼šé¢å¤–50%æˆæœ¬èŠ‚çœ
- ğŸ§© **Strategic Chunking**ï¼šé¿å…ä½¿ç”¨context windowæœ€å1/5
- ğŸ’­ **Extended Thinking**ï¼šthinking tokensåªè®¡è´¹ä¸€æ¬¡
- ğŸ’µ **å®šä»·**ï¼š>200k tokensæ—¶ä»·æ ¼ä¸Šæ¶¨ï¼ˆ$3â†’$6è¾“å…¥ï¼Œ$15â†’$22.5è¾“å‡ºï¼‰

### 2. ä¸­æ–‡åˆ›ä½œåœºæ™¯ç‰¹ç‚¹

**Tokenç®¡ç†ç­–ç•¥ï¼š**
- ğŸ”„ **åŠ¨æ€è£å‰ª**ï¼šé•¿å¯¹è¯é€æ­¥é™ä½æ—§å†…å®¹ä¼˜å…ˆçº§
- ğŸªŸ **çª—å£é™åˆ¶**ï¼šé¿å…contextè¿‡é•¿å¯¼è‡´æ€§èƒ½ä¸‹é™
- ğŸ‡¨ğŸ‡³ **ä¸­æ–‡ç‰¹æ€§**ï¼šåˆ†è¯æ¯”è‹±æ–‡å¤æ‚ï¼Œtokenæ¶ˆè€—æ›´é«˜

**ç”¨æˆ·åœºæ™¯åˆ†æï¼š**
- ğŸ“ **åˆ›ä½œå·¥ä½œ**ï¼šå°è¯´ã€å‰§æœ¬ã€æ–‡ç« ã€ä»£ç ç­‰é•¿æ–‡æœ¬ç”Ÿæˆ
- ğŸ’¬ **è¿ç»­å¯¹è¯**ï¼šéœ€è¦ä¿æŒå®Œæ•´ä¸Šä¸‹æ–‡
- ğŸ¯ **é«˜è´¨é‡è¦æ±‚**ï¼šä¸èƒ½ä¸¢å¤±å…³é”®ä¸Šä¸‹æ–‡ä¿¡æ¯

---

## ğŸ” å½“å‰ç³»ç»Ÿç“¶é¢ˆåˆ†æ

### ç“¶é¢ˆ1ï¼šTokené™åˆ¶è¿‡äºä¿å®ˆ ğŸš¨ **é«˜ä¼˜å…ˆçº§**

**ç°çŠ¶ï¼š**
```typescript
// lib/constants/message-limits.ts
DEFAULT: {
  maxMessages: 80,
  maxTokens: 32000,      // âŒ å¤ªä¿å®ˆï¼Claudeæ”¯æŒ200k
  reserveTokens: 8000
}
```

**é—®é¢˜ï¼š**
- Claude Opus 4 / Sonnet 4.5: 200k context window
- Gemini 2.5 Pro: 1M context window
- å½“å‰é…ç½®ï¼šåªç”¨äº†15-32%çš„å®¹é‡
- **åˆ›ä½œåœºæ™¯å—é™**ï¼šé•¿æ–‡æœ¬å¯¹è¯é¢‘ç¹è¢«è£å‰ª

---

### ç“¶é¢ˆ2ï¼šè£å‰ªç­–ç•¥ç¼ºä¹æ™ºèƒ½åŒ– ğŸš¨ **ä¸­ä¼˜å…ˆçº§**

**ç°çŠ¶ï¼š**
```typescript
// lib/chat/context-trimmer.ts
// ç®€å•çš„FIFOè£å‰ªï¼šä»æœ€æ—§çš„æ¶ˆæ¯å¼€å§‹ä¸¢å¼ƒ
const reversedOthers = [...otherMessages].reverse()
```

**é—®é¢˜ï¼š**
- âŒ **æ— æƒé‡æœºåˆ¶**ï¼šæ‰€æœ‰æ¶ˆæ¯å¹³ç­‰å¯¹å¾…
- âŒ **æ— é‡è¦æ€§åˆ¤æ–­**ï¼šå¯èƒ½ä¸¢å¤±å…³é”®ä¸Šä¸‹æ–‡
- âŒ **å›ºå®šçª—å£**ï¼šä¸è€ƒè™‘æ¶ˆæ¯å†…å®¹é•¿çŸ­

**ä¸šç•Œæœ€ä½³å®è·µï¼š**
- âœ… **åŠ¨æ€ä¼˜å…ˆçº§**ï¼šæ ¹æ®æ¶ˆæ¯é‡è¦æ€§æ‰“åˆ†
- âœ… **æ‘˜è¦å‹ç¼©**ï¼šä¿ç•™æ—§æ¶ˆæ¯æ‘˜è¦è€Œä¸æ˜¯å®Œå…¨åˆ é™¤
- âœ… **è¯­ä¹‰ä¿æŒ**ï¼šä¿ç•™å¯¹å½“å‰å¯¹è¯å…³é”®çš„å†å²ä¿¡æ¯

---

### ç“¶é¢ˆ3ï¼šTokenä¼°ç®—ä¸å‡†ç¡® âš ï¸ **ä¸­ä¼˜å…ˆçº§**

**ç°çŠ¶ï¼š**
```typescript
// ç®€å•è§„åˆ™ï¼šä¸­æ–‡1.5å­—ç¬¦/tokenï¼Œè‹±æ–‡4å­—ç¬¦/token
const chineseChars = (content.match(/[\u4e00-\u9fa5]/g) || []).length
const otherChars = content.length - chineseChars
return Math.ceil(chineseChars / 1.5 + otherChars / 4)
```

**é—®é¢˜ï¼š**
- âŒ **ä¼°ç®—è¯¯å·®å¤§**ï¼šä¸åŒåˆ†è¯å™¨å·®å¼‚æ˜¾è‘—
- âŒ **ä¿å®ˆé…ç½®**ï¼šä¸ºé¿å…è¶…é™ï¼Œé¢„ç•™è¿‡å¤šbuffer
- âŒ **æˆæœ¬æµªè´¹**ï¼šå®é™…ä½¿ç”¨è¿œä½äºä¼°ç®—å€¼

**è§£å†³æ–¹å‘ï¼š**
- âœ… ä½¿ç”¨å®˜æ–¹tokenizeråº“ï¼ˆjs-tiktoken for GPT, anthropic-tokenizer for Claudeï¼‰
- âœ… æŒ‰æ¨¡å‹ç²¾ç¡®è®¡ç®—tokenæ•°
- âœ… å‡å°‘bufferæµªè´¹

---

### ç“¶é¢ˆ4ï¼šè™šæ‹Ÿæ»šåŠ¨é˜ˆå€¼åé«˜ âš ï¸ **ä½ä¼˜å…ˆçº§**

**ç°çŠ¶ï¼š**
```typescript
// lib/config/chat-config.ts
threshold: 100,  // 100æ¡æ¶ˆæ¯åæ‰å¯ç”¨è™šæ‹Ÿæ»šåŠ¨
```

**é—®é¢˜ï¼š**
- ğŸ“± **ç§»åŠ¨ç«¯æ€§èƒ½**ï¼šåœ¨ä½ç«¯è®¾å¤‡ä¸Šï¼Œ50+æ¡æ¶ˆæ¯å°±å¡é¡¿
- ğŸ’» **æ¡Œé¢ç«¯å°šå¯**ï¼šç°ä»£æµè§ˆå™¨å¤„ç†100æ¡æ¶ˆæ¯æ— å‹åŠ›

**ä¼˜åŒ–æ–¹å‘ï¼š**
- âœ… æ ¹æ®è®¾å¤‡æ€§èƒ½åŠ¨æ€è°ƒæ•´é˜ˆå€¼
- âœ… ç§»åŠ¨ç«¯ï¼š50æ¡å¯ç”¨
- âœ… æ¡Œé¢ç«¯ï¼š100-150æ¡å¯ç”¨

---

### ç“¶é¢ˆ5ï¼šç¼ºå°‘Prompt Cachingæ”¯æŒ ğŸ’¡ **æœªæ¥ä¼˜åŒ–**

**ç°çŠ¶ï¼š**
- âŒ æœªä½¿ç”¨Claudeçš„Prompt CachingåŠŸèƒ½
- âŒ é‡å¤å‘é€ç›¸åŒçš„é•¿ä¸Šä¸‹æ–‡

**æ½œåœ¨æ”¶ç›Šï¼š**
- âš¡ **å»¶è¿Ÿé™ä½**ï¼šç¼“å­˜å‘½ä¸­æ—¶å“åº”æ›´å¿«
- ğŸ’° **æˆæœ¬èŠ‚çœ**ï¼šç¼“å­˜çš„tokensä¸é‡å¤è®¡è´¹
- ğŸ“ˆ **ç”¨æˆ·ä½“éªŒ**ï¼šåˆ›ä½œåœºæ™¯ä¸‹åå¤ä¿®æ”¹æ—¶æ•ˆæœæ˜¾è‘—

---

## ğŸ¯ ä¼˜åŒ–æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰

### ä¼˜å…ˆçº§1ï¼šæå‡Tokené™åˆ¶ ğŸš€

**ç›®æ ‡ï¼š**
å……åˆ†åˆ©ç”¨Claude/Geminiçš„å¤§ä¸Šä¸‹æ–‡çª—å£èƒ½åŠ›

**å®æ–½æ–¹æ¡ˆï¼š**

#### 1.1 æ›´æ–°æ¨¡å‹é…ç½®
```typescript
// lib/constants/message-limits.ts
MODEL_CONFIGS: {
  'claude-opus-4-1-20250805': {
    contextWindow: 200000,
    reserveTokens: 8000,
    maxTokens: 8000,
    // âœ… æ–°å¢ï¼šåˆ›ä½œæ¨¡å¼é…ç½®
    creativeMode: {
      maxTokens: 180000,  // ä½¿ç”¨90%å®¹é‡
      reserveTokens: 20000 // é¢„ç•™æ›´å¤šè¾“å‡ºç©ºé—´
    }
  },
  'claude-sonnet-4-5-20250929': {
    contextWindow: 200000,
    reserveTokens: 8000,
    maxTokens: 8000,
    creativeMode: {
      maxTokens: 180000,
      reserveTokens: 20000
    }
  },
  'gemini-2.5-pro': {
    contextWindow: 1000000,
    reserveTokens: 8000,
    maxTokens: 8000,
    creativeMode: {
      maxTokens: 900000,  // ä½¿ç”¨90%å®¹é‡
      reserveTokens: 100000
    }
  }
}
```

#### 1.2 æ·»åŠ åˆ›ä½œæ¨¡å¼åˆ‡æ¢
```typescript
// ç”¨æˆ·å¯åœ¨è®¾ç½®ä¸­å¯ç”¨"åˆ›ä½œæ¨¡å¼"
export interface ChatSettings {
  modelId: string
  temperature: number
  contextAware: boolean
  maxTokens?: number
  creativeMode?: boolean  // âœ… æ–°å¢
}
```

**é¢„æœŸæ•ˆæœï¼š**
- âœ… **10å€æå‡**ï¼š32k â†’ 180k tokens
- âœ… **é•¿æ–‡æœ¬æ”¯æŒ**ï¼šå¯ä»¥å¤„ç†20-30è½®æ·±åº¦å¯¹è¯
- âœ… **åˆ›ä½œåœºæ™¯ä¼˜åŒ–**ï¼šå°è¯´/å‰§æœ¬/ä»£ç ç­‰é•¿å†…å®¹ç”Ÿæˆ

---

### ä¼˜å…ˆçº§2ï¼šæ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç† ğŸ§ 

**ç›®æ ‡ï¼š**
åœ¨tokené™åˆ¶å†…ä¿ç•™æœ€æœ‰ä»·å€¼çš„ä¿¡æ¯

**å®æ–½æ–¹æ¡ˆï¼š**

#### 2.1 æ¶ˆæ¯é‡è¦æ€§è¯„åˆ†
```typescript
interface MessageScore {
  recency: number      // æ—¶é—´æƒé‡ (0-1)
  role: number         // è§’è‰²æƒé‡ (system:1, user:0.9, assistant:0.8)
  length: number       // é•¿åº¦æƒé‡ (é•¿æ¶ˆæ¯æ›´é‡è¦)
  semantic: number     // è¯­ä¹‰æƒé‡ (ä¸å½“å‰å¯¹è¯çš„ç›¸å…³æ€§)
  total: number        // æ€»åˆ†
}

function calculateMessageScore(
  message: ChatMessage,
  index: number,
  totalMessages: number,
  currentQuery?: string
): MessageScore {
  // æ—¶é—´æƒé‡ï¼šè¶Šæ–°è¶Šé‡è¦
  const recency = (index + 1) / totalMessages

  // è§’è‰²æƒé‡
  const roleWeights = { system: 1, user: 0.9, assistant: 0.8 }
  const role = roleWeights[message.role] || 0.5

  // é•¿åº¦æƒé‡ï¼šé•¿æ¶ˆæ¯åŒ…å«æ›´å¤šä¿¡æ¯
  const length = Math.min(1, message.content.length / 1000)

  // è¯­ä¹‰æƒé‡ï¼šç®€åŒ–ç‰ˆï¼Œæ£€æŸ¥å…³é”®è¯é‡å 
  const semantic = currentQuery
    ? calculateSemanticSimilarity(message.content, currentQuery)
    : 0.5

  const total = (recency * 0.4) + (role * 0.2) + (length * 0.2) + (semantic * 0.2)

  return { recency, role, length, semantic, total }
}
```

#### 2.2 æ™ºèƒ½è£å‰ªç­–ç•¥
```typescript
export function smartTrimMessages(
  messages: ChatMessage[],
  maxTokens: number,
  currentQuery?: string
): TrimResult {
  // 1. è®¡ç®—æ‰€æœ‰æ¶ˆæ¯çš„åˆ†æ•°
  const scoredMessages = messages.map((msg, idx) => ({
    message: msg,
    score: calculateMessageScore(msg, idx, messages.length, currentQuery),
    tokens: estimateTokens(msg.content)
  }))

  // 2. æŒ‰åˆ†æ•°æ’åº
  scoredMessages.sort((a, b) => b.score.total - a.score.total)

  // 3. è´ªå¿ƒé€‰æ‹©ï¼šä¼˜å…ˆä¿ç•™é«˜åˆ†æ¶ˆæ¯
  const selected: typeof scoredMessages = []
  let currentTokens = 0

  for (const item of scoredMessages) {
    if (currentTokens + item.tokens <= maxTokens) {
      selected.push(item)
      currentTokens += item.tokens
    }
  }

  // 4. æŒ‰æ—¶é—´é¡ºåºé‡æ–°æ’åˆ—
  selected.sort((a, b) =>
    messages.indexOf(a.message) - messages.indexOf(b.message)
  )

  return {
    messages: selected.map(s => s.message),
    trimmed: selected.length < messages.length,
    originalLength: messages.length,
    estimatedTokens: currentTokens,
    dropCount: messages.length - selected.length
  }
}
```

**é¢„æœŸæ•ˆæœï¼š**
- âœ… **ä¸Šä¸‹æ–‡è¿è´¯æ€§**ï¼šä¿ç•™å…³é”®å¯¹è¯å†å²
- âœ… **è¯­ä¹‰å®Œæ•´æ€§**ï¼šä¸ä¼šçªç„¶ä¸¢å¤±é‡è¦ä¿¡æ¯
- âœ… **ç”¨æˆ·ä½“éªŒ**ï¼šåˆ›ä½œè¿‡ç¨‹æ›´æµç•…

---

### ä¼˜å…ˆçº§3ï¼šç²¾ç¡®Tokenè®¡ç®— ğŸ“Š

**ç›®æ ‡ï¼š**
å‡å°‘ä¼°ç®—è¯¯å·®å’Œbufferæµªè´¹

**å®æ–½æ–¹æ¡ˆï¼š**

#### 3.1 ä½¿ç”¨å®˜æ–¹Tokenizer
```bash
pnpm add js-tiktoken @anthropic-ai/tokenizer
```

```typescript
// lib/utils/token-counter.ts
import { encodingForModel } from 'js-tiktoken'
import { countTokens as claudeCountTokens } from '@anthropic-ai/tokenizer'

export function accurateTokenCount(
  content: string,
  model: string
): number {
  // Claude models
  if (model.includes('claude')) {
    return claudeCountTokens(content)
  }

  // GPT models
  if (model.includes('gpt')) {
    const encoding = encodingForModel(model as any)
    const tokens = encoding.encode(content)
    encoding.free()
    return tokens.length
  }

  // Gemini / others: fallback to estimation
  return estimateTokens(content)
}
```

#### 3.2 åŠ¨æ€è°ƒæ•´Reserve Tokens
```typescript
// æ ¹æ®å®é™…è¾“å‡ºé•¿åº¦è°ƒæ•´é¢„ç•™
function adaptiveReserveTokens(
  conversationHistory: ChatMessage[],
  model: string
): number {
  // åˆ†æå†å²è¾“å‡ºé•¿åº¦
  const assistantMessages = conversationHistory.filter(m => m.role === 'assistant')
  const avgLength = assistantMessages.length > 0
    ? assistantMessages.reduce((sum, m) => sum + estimateTokens(m.content), 0) / assistantMessages.length
    : 4000

  // é¢„ç•™1.5å€çš„å¹³å‡è¾“å‡ºé•¿åº¦
  return Math.min(20000, Math.ceil(avgLength * 1.5))
}
```

**é¢„æœŸæ•ˆæœï¼š**
- âœ… **æˆæœ¬ä¼˜åŒ–**ï¼šå‡å°‘10-20%çš„tokenæµªè´¹
- âœ… **ç²¾ç¡®é™æµ**ï¼šé¿å…æ„å¤–è¶…é™
- âœ… **æ›´å¤§å¯ç”¨ç©ºé—´**ï¼šå¯ä»¥å®¹çº³æ›´å¤šä¸Šä¸‹æ–‡

---

### ä¼˜å…ˆçº§4ï¼šæ€§èƒ½ä¼˜åŒ– âš¡

**ç›®æ ‡ï¼š**
æå‡é•¿å¯¹è¯åœºæ™¯çš„å“åº”é€Ÿåº¦

**å®æ–½æ–¹æ¡ˆï¼š**

#### 4.1 åŠ¨æ€è™šæ‹Ÿæ»šåŠ¨é˜ˆå€¼
```typescript
// lib/config/chat-config.ts
export function getVirtualScrollThreshold(): number {
  // æ£€æµ‹è®¾å¤‡æ€§èƒ½
  if (typeof window === 'undefined') return 100

  const isMobile = /Android|iPhone|iPad/i.test(navigator.userAgent)
  const hasHighPerformance = navigator.hardwareConcurrency >= 4

  if (isMobile) {
    return hasHighPerformance ? 70 : 50
  }

  return hasHighPerformance ? 150 : 100
}
```

#### 4.2 æ¶ˆæ¯é¢„åŠ è½½å’Œæ‡’åŠ è½½
```typescript
// åªåŠ è½½æœ€è¿‘çš„æ¶ˆæ¯ï¼Œæ—§æ¶ˆæ¯æŒ‰éœ€åŠ è½½
export function usePaginatedMessages(
  conversationId: string,
  initialLimit: number = 50
) {
  const [page, setPage] = useState(1)
  const [hasMore, setHasMore] = useState(true)

  const { data, isLoading } = useQuery({
    queryKey: ['messages', conversationId, page],
    queryFn: async () => {
      const response = await fetch(
        `/api/conversations/${conversationId}/messages?page=${page}&limit=${initialLimit}`
      )
      return response.json()
    }
  })

  const loadMore = () => {
    if (hasMore && !isLoading) {
      setPage(p => p + 1)
    }
  }

  return { messages: data?.messages || [], loadMore, isLoading, hasMore }
}
```

---

### ä¼˜å…ˆçº§5ï¼šPrompt Cachingé›†æˆ ğŸ’°

**ç›®æ ‡ï¼š**
é™ä½æˆæœ¬ï¼Œæå‡å“åº”é€Ÿåº¦

**å®æ–½æ–¹æ¡ˆï¼š**

#### 5.1 APIè¯·æ±‚æ·»åŠ ç¼“å­˜æ ‡è®°
```typescript
// app/api/chat/route.ts
const aiResponse = await fetch(`${API_BASE}/chat/completions`, {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${apiKey}`,
    "Content-Type": "application/json",
    "anthropic-beta": "prompt-caching-2024-07-31"  // âœ… å¯ç”¨ç¼“å­˜
  },
  body: JSON.stringify({
    model,
    messages: finalMessages,
    temperature,
    max_tokens: maxTokens,
    stream: true,
    // âœ… æ ‡è®°å¯ç¼“å­˜çš„ç³»ç»Ÿæ¶ˆæ¯
    system: [{
      type: "text",
      text: systemPrompt,
      cache_control: { type: "ephemeral" }
    }]
  })
})
```

#### 5.2 ç¼“å­˜ç­–ç•¥
- âœ… **System Promptç¼“å­˜**ï¼šåˆ›ä½œæ¨¡æ¿ã€è§’è‰²è®¾å®šç­‰å›ºå®šå†…å®¹
- âœ… **é•¿ä¸Šä¸‹æ–‡ç¼“å­˜**ï¼šè¶…è¿‡10è½®å¯¹è¯åï¼Œç¼“å­˜å‰Nè½®å†å²
- âœ… **æ–‡æ¡£ç¼“å­˜**ï¼šå‚è€ƒèµ„æ–™ã€ä»£ç åº“ç­‰å¤§é‡é™æ€å†…å®¹

**é¢„æœŸæ•ˆæœï¼š**
- ğŸ’° **æˆæœ¬é™ä½50%**ï¼šç¼“å­˜å‘½ä¸­æ—¶åªè®¡è´¹æ–°å¢tokens
- âš¡ **å»¶è¿Ÿé™ä½**ï¼šç¼“å­˜å‘½ä¸­æ—¶å“åº”æ›´å¿«
- ğŸ“ˆ **åˆ›ä½œä½“éªŒæå‡**ï¼šåå¤ä¿®æ”¹æ—¶æ›´æµç•…

---

## ğŸ“ˆ é¢„æœŸæ”¶ç›Šå¯¹æ¯”

| æŒ‡æ ‡ | å½“å‰ | ä¼˜åŒ–å | æå‡ |
|------|------|--------|------|
| **æœ€å¤§ä¸Šä¸‹æ–‡** | 32k tokens | 180k tokens | **5.6å€** |
| **æ”¯æŒå¯¹è¯è½®æ•°** | 8-10è½® | 40-50è½® | **5å€** |
| **Tokenåˆ©ç”¨ç‡** | ~60% | ~85% | **+25%** |
| **è£å‰ªå‡†ç¡®æ€§** | ç®€å•FIFO | æ™ºèƒ½è¯„åˆ† | **è¯­ä¹‰å®Œæ•´æ€§â†‘** |
| **å“åº”å»¶è¿Ÿ** | 2-3s | 1.5-2s (ç¼“å­˜) | **-40%** |
| **è™šæ‹Ÿæ»šåŠ¨é˜ˆå€¼** | 100æ¡ | 50-150æ¡(åŠ¨æ€) | **æ€§èƒ½ä¼˜åŒ–** |
| **æˆæœ¬** | åŸºçº¿ | -30% (ç¼“å­˜) | **èŠ‚çœ30%** |

---

## ğŸš€ å®æ–½è®¡åˆ’ï¼ˆåˆ†3ä¸ªé˜¶æ®µï¼‰

### Phase 1: å¿«é€Ÿèƒœåˆ©ï¼ˆ1-2å¤©ï¼‰ ğŸ¯
- [x] æå‡tokené™åˆ¶é…ç½®ï¼ˆmessage-limits.tsï¼‰
- [x] æ·»åŠ åˆ›ä½œæ¨¡å¼å¼€å…³
- [ ] æ›´æ–°APIè°ƒç”¨é€»è¾‘ä»¥æ”¯æŒæ›´å¤§ä¸Šä¸‹æ–‡
- [ ] ç”¨æˆ·è®¾ç½®ç•Œé¢æ·»åŠ "åˆ›ä½œæ¨¡å¼"å¼€å…³

### Phase 2: æ ¸å¿ƒä¼˜åŒ–ï¼ˆ3-5å¤©ï¼‰ ğŸ§ 
- [ ] å®ç°æ™ºèƒ½æ¶ˆæ¯è¯„åˆ†ç³»ç»Ÿ
- [ ] é‡æ„context-trimmerä½¿ç”¨æ™ºèƒ½ç­–ç•¥
- [ ] é›†æˆå®˜æ–¹tokenizeråº“
- [ ] åŠ¨æ€è°ƒæ•´reserve tokens

### Phase 3: é«˜çº§ç‰¹æ€§ï¼ˆ1å‘¨+ï¼‰ ğŸ’
- [ ] å®ç°æ¶ˆæ¯åˆ†é¡µåŠ è½½
- [ ] é›†æˆPrompt Caching
- [ ] æ€§èƒ½ç›‘æ§å’Œè‡ªé€‚åº”ä¼˜åŒ–
- [ ] A/Bæµ‹è¯•éªŒè¯æ•ˆæœ

---

## âš ï¸ é£é™©å’Œæ³¨æ„äº‹é¡¹

### é£é™©1ï¼šæˆæœ¬å¢åŠ 
- **åŸå› **ï¼šæ›´å¤§çš„ä¸Šä¸‹æ–‡çª—å£ = æ›´å¤štokenæ¶ˆè€—
- **ç¼“è§£**ï¼š
  - âœ… åˆ›ä½œæ¨¡å¼ä½œä¸ºå¯é€‰åŠŸèƒ½
  - âœ… ç”¨æˆ·é…é¢ç®¡ç†
  - âœ… Prompt Cachingé™ä½æˆæœ¬

### é£é™©2ï¼šå“åº”å»¶è¿Ÿ
- **åŸå› **ï¼šå¤„ç†æ›´å¤šä¸Šä¸‹æ–‡éœ€è¦æ›´é•¿æ—¶é—´
- **ç¼“è§£**ï¼š
  - âœ… Streamingè¾“å‡ºä¿æŒä½“éªŒ
  - âœ… Prompt CachingåŠ é€Ÿ
  - âœ… æ™ºèƒ½è£å‰ªé¿å…ä¸å¿…è¦çš„ä¸Šä¸‹æ–‡

### é£é™©3ï¼šå†…å­˜å ç”¨
- **åŸå› **ï¼šå®¢æˆ·ç«¯å­˜å‚¨å¤§é‡æ¶ˆæ¯
- **ç¼“è§£**ï¼š
  - âœ… è™šæ‹Ÿæ»šåŠ¨
  - âœ… åˆ†é¡µåŠ è½½
  - âœ… æ¶ˆæ¯å‹ç¼©å­˜å‚¨

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡

1. **ç”¨æˆ·æ»¡æ„åº¦**
   - åˆ›ä½œåœºæ™¯ä¸‹çš„ä¸­æ–­ç‡é™ä½ > 80%
   - ä¸Šä¸‹æ–‡è¿è´¯æ€§è¯„åˆ† > 4.5/5

2. **æŠ€æœ¯æŒ‡æ ‡**
   - å¹³å‡å¯¹è¯è½®æ•°: 10 â†’ 30+
   - Tokenåˆ©ç”¨ç‡: 60% â†’ 85%
   - å“åº”å»¶è¿Ÿ: < 2s (P95)

3. **æˆæœ¬æ§åˆ¶**
   - å•ç”¨æˆ·æœˆæˆæœ¬å¢é•¿ < 50%
   - Prompt Cachingé™ä½æˆæœ¬ 30%

---

## ğŸ¬ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¼€å§‹ï¼ˆPhase 1ï¼‰
1. âœ… æ›´æ–° message-limits.ts é…ç½®
2. âœ… æ·»åŠ åˆ›ä½œæ¨¡å¼ç±»å‹å®šä¹‰
3. ğŸ”„ ä¿®æ”¹ chat API ä»¥æ”¯æŒåˆ›ä½œæ¨¡å¼
4. ğŸ”„ å‰ç«¯UIæ·»åŠ åˆ›ä½œæ¨¡å¼å¼€å…³

**éœ€è¦ä½ çš„åé¦ˆï¼š**
- æ˜¯å¦åŒæ„è¿™ä¸ªä¼˜åŒ–æ–¹å‘ï¼Ÿ
- ä¼˜å…ˆçº§æ’åºæ˜¯å¦åˆç†ï¼Ÿ
- é¢„ç®—å’Œæ—¶é—´é™åˆ¶ï¼Ÿ
- æ˜¯å¦éœ€è¦è°ƒæ•´æŸäº›æ–¹æ¡ˆï¼Ÿ