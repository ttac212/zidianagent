/**
 * Linuså¼APIè·¯ç”±æµ‹è¯• - éªŒè¯å•è¡¨å†™å…¥å’ŒåŸºæœ¬åŠŸèƒ½
 *
 * è¿è¡Œæ–¹æ³•ï¼š
 * npm test -- tests/api-chat-linus.test.ts
 * æˆ–
 * vitest run tests/api-chat-linus.test.ts
 */

import { describe, it, expect, beforeEach, vi } from 'vitest'
import { NextRequest } from 'next/server'

// å…ˆè®¾ç½®mocks
vi.mock('@/lib/prisma', () => ({
  prisma: {
    conversation: {
      create: vi.fn(),
      findFirst: vi.fn(),
      update: vi.fn()
    },
    message: {
      create: vi.fn(),
      aggregate: vi.fn(),
    },
    user: {
      update: vi.fn()
    }
  }
}))

vi.mock('next-auth/jwt', () => ({
  getToken: vi.fn()
}))

vi.mock('@/lib/security/rate-limiter', () => ({
  checkMultipleRateLimits: vi.fn().mockResolvedValue({ allowed: true })
}))

vi.mock('@/lib/model-validator', () => ({
  validateModelId: vi.fn().mockReturnValue({ isValid: true })
}))

vi.mock('@/lib/security/message-validator', () => ({
  validateChatMessages: vi.fn().mockReturnValue({
    messages: [{ role: 'user', content: 'test message' }],
    stats: { roleViolations: 0 }
  })
}))

vi.mock('@/lib/ai/key-manager', () => ({
  selectApiKey: vi.fn().mockReturnValue({ apiKey: 'test-key' })
}))

// Mock fetch for upstream API
global.fetch = vi.fn()

// ç°åœ¨å¯¼å…¥è¢«æµ‹è¯•çš„æ¨¡å—
import { POST, GET } from '@/app/api/chat/route'
import { prisma } from '@/lib/prisma'
import { getToken } from 'next-auth/jwt'

describe('Linuså¼èŠå¤©APIé‡æ„æµ‹è¯•', () => {
  const mockUser = {
    id: 'test-user-id',
    status: 'ACTIVE',
    monthlyTokenLimit: 10000
  }

  const mockConversation = {
    id: 'test-conv-id',
    userId: 'test-user-id',
    user: mockUser
  }

  beforeEach(() => {
    vi.clearAllMocks()

    // è®¾ç½®è®¤è¯
    vi.mocked(getToken).mockResolvedValue({ sub: 'test-user-id' } as any)

    // è®¾ç½®æ•°æ®åº“mocks
    vi.mocked(prisma.conversation.create).mockResolvedValue(mockConversation as any)
    vi.mocked(prisma.conversation.findFirst).mockResolvedValue(mockConversation as any)
    vi.mocked(prisma.message.aggregate).mockResolvedValue({ _sum: { totalTokens: 0 } } as any)
    vi.mocked(prisma.message.create).mockResolvedValue({ id: 'test-message-id' } as any)
  })

  describe('GET /api/chat', () => {
    it('åº”è¯¥è¿”å›å¥åº·æ£€æŸ¥çŠ¶æ€', async () => {
      const response = await GET()
      const data = await response.json()

      expect(response.status).toBe(200)
      expect(data).toEqual({ status: 'ok' })
    })
  })

  describe('POST /api/chat', () => {
    it('åº”è¯¥æ‹’ç»æœªè®¤è¯çš„è¯·æ±‚', async () => {
      vi.mocked(getToken).mockResolvedValue(null)

      const request = new NextRequest('http://localhost/api/chat', {
        method: 'POST',
        body: JSON.stringify({ messages: [], model: 'gpt-3.5-turbo' })
      })

      const response = await POST(request)
      const data = await response.json()

      expect(response.status).toBe(401)
      expect(data.error).toBe('æœªè®¤è¯')
    })

    it('åº”è¯¥æˆåŠŸå¤„ç†ç®€å•èŠå¤©è¯·æ±‚', async () => {
      // Mockä¸Šæ¸¸APIå“åº”
      const mockStream = new ReadableStream({
        start(controller) {
          controller.enqueue(new TextEncoder().encode('data: {"choices":[{"delta":{"content":"Hello"}}]}\n\n'))
          controller.enqueue(new TextEncoder().encode('data: [DONE]\n\n'))
          controller.close()
        }
      })

      vi.mocked(global.fetch).mockResolvedValue(
        new Response(mockStream, {
          ok: true,
          headers: new Headers({ 'content-type': 'text/event-stream' })
        } as any) as any
      )

      const request = new NextRequest('http://localhost/api/chat', {
        method: 'POST',
        headers: { 'content-type': 'application/json' },
        body: JSON.stringify({
          messages: [{ role: 'user', content: 'Hello' }],
          model: 'gpt-3.5-turbo',
          conversationId: 'test-conv-id'
        })
      })

      const response = await POST(request)

      expect(response.status).toBe(200)
      expect(response.headers.get('content-type')).toBe('text/event-stream')
    })

    it('åº”è¯¥éªŒè¯å•è¡¨å†™å…¥æ‰¿è¯º', async () => {
      const mockStream = new ReadableStream({
        start(controller) {
          controller.close()
        }
      })

      vi.mocked(global.fetch).mockResolvedValue(
        new Response(mockStream, { ok: true } as any) as any
      )

      const request = new NextRequest('http://localhost/api/chat', {
        method: 'POST',
        headers: { 'content-type': 'application/json' },
        body: JSON.stringify({
          messages: [{ role: 'user', content: 'Test message' }],
          model: 'gpt-3.5-turbo',
          conversationId: 'test-conv-id'
        })
      })

      await POST(request)

      // ç»™å¼‚æ­¥æ“ä½œæ—¶é—´å®Œæˆ
      await new Promise(resolve => setTimeout(resolve, 100))

      // éªŒè¯åªè°ƒç”¨äº† Message.createï¼Œæ²¡æœ‰è°ƒç”¨å…¶ä»–è¡¨çš„æ›´æ–°
      expect(prisma.message.create).toHaveBeenCalledWith({
        data: expect.objectContaining({
          conversationId: 'test-conv-id',
          userId: 'test-user-id',  // é‡è¦ï¼šéªŒè¯userIdç›´æ¥å­˜å‚¨
          role: 'USER',
          content: 'test message',
          modelId: 'gpt-3.5-turbo'
        })
      })

      // å…³é”®æµ‹è¯•ï¼šéªŒè¯æ²¡æœ‰è°ƒç”¨Useræˆ–Conversationçš„updateæ–¹æ³•
      expect(prisma.conversation.update).not.toHaveBeenCalled()
      expect(prisma.user.update).not.toHaveBeenCalled()
    })

    it('åº”è¯¥ä½¿ç”¨ä¼˜åŒ–çš„é…é¢æŸ¥è¯¢ï¼ˆç›´æ¥userIdï¼Œæ— JOINï¼‰', async () => {
      const request = new NextRequest('http://localhost/api/chat', {
        method: 'POST',
        headers: { 'content-type': 'application/json' },
        body: JSON.stringify({
          messages: [{ role: 'user', content: 'Test' }],
          model: 'gpt-3.5-turbo',
          conversationId: 'test-conv-id'
        })
      })

      // Mockä¸Šæ¸¸APIå¤±è´¥ï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿æ‰§è¡Œåˆ°é…é¢æ£€æŸ¥
      vi.mocked(global.fetch).mockRejectedValue(new Error('upstream error'))

      try {
        await POST(request)
      } catch (e) {
        // å¿½ç•¥ä¸Šæ¸¸é”™è¯¯ï¼Œæˆ‘ä»¬åªå…³å¿ƒé…é¢æŸ¥è¯¢
      }

      // éªŒè¯é…é¢æŸ¥è¯¢ä½¿ç”¨äº†ä¼˜åŒ–çš„ç›´æ¥userIdæŸ¥è¯¢
      expect(prisma.message.aggregate).toHaveBeenCalledWith({
        where: {
          userId: 'test-user-id',  // ç›´æ¥æŸ¥è¯¢ï¼Œä¸é€šè¿‡conversation JOIN
          createdAt: expect.any(Object)
        },
        _sum: { totalTokens: true }
      })
    })

    it('åº”è¯¥æ­£ç¡®å¤„ç†é…é¢è¶…é™', async () => {
      // æ¨¡æ‹Ÿé…é¢è¶…é™
      vi.mocked(prisma.message.aggregate).mockResolvedValue({
        _sum: { totalTokens: 15000 } // è¶…è¿‡10000é™åˆ¶
      } as any)

      const request = new NextRequest('http://localhost/api/chat', {
        method: 'POST',
        headers: { 'content-type': 'application/json' },
        body: JSON.stringify({
          messages: [{ role: 'user', content: 'Test' }],
          model: 'gpt-3.5-turbo',
          conversationId: 'test-conv-id'
        })
      })

      const response = await POST(request)
      const data = await response.json()

      expect(response.status).toBe(429)
      expect(data.error).toBe('æœˆåº¦é…é¢å·²ç”¨å®Œ')
    })
  })
})

describe('æ¶æ„ç®€åŒ–éªŒè¯', () => {
  it('æ–°APIåº”è¯¥æ¯”æ—§APIç®€æ´å¾—å¤š', () => {
    // è¿™æ˜¯ä¸€ä¸ªå®šæ€§æµ‹è¯•ï¼Œç¡®ä¿æˆ‘ä»¬çš„æ‰¿è¯ºå¾—åˆ°å±¥è¡Œ
    const newApiLength = 186 // å®é™…è¡Œæ•°
    const oldApiLength = 393 // æ—§APIçš„å®é™…è¡Œæ•°

    const simplificationRatio = (oldApiLength - newApiLength) / oldApiLength

    expect(simplificationRatio).toBeGreaterThan(0.4) // è‡³å°‘å‡å°‘40%çš„ä»£ç 
    console.log(`ğŸ“Š ä»£ç ç®€åŒ–: ${(simplificationRatio * 100).toFixed(1)}% (${oldApiLength} â†’ ${newApiLength} è¡Œ)`)
  })
})